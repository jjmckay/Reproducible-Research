---
title: 'Coursera''s Reproducible Research: Peer Assignment 2'
author: "JJMcKay"
date: "Friday, September 12, 2014"
output: html_document
---

```{r setoptslibs}
library(gridExtra)
library(ggplot2)
options(rpubs.upload.method = "internal")
```

##Synopsis
In our report we sought to find the types of storm events with the highest
negative impact in categories of human health and to local economies. Using the
Storm Events Database dataset, we were able to determine that the type of
storm event with the highest impact to human health are 1) tornadoes,
thunderstorm wind, and hail and 2) hurricanes and tropical storms. The former
occurs with the greatest frequency and still his the highest average impact
to health per storm event. In terms of economical impact, our model determined
that flooding and heavy rain along with the previous two have the highest
negative impact. Overall, tornadoes appear to be the worst threat to both
health and economies of all storm events.



##Data Processing

We begin to answer our question using the dataset of observed storm events
from the [National Climactic Data Center](http://www.ncdc.noaa.gov/) of the
[National Oceanic Atmospheric Administration](http://www.noaa.gov/). The
dataset and others like it (most broken down by year) are available from
[Storm Events Database](http://www.ncdc.noaa.gov/stormevents/)
at the National Weather Service website. Specific Storm Events Database URLs
used in this anlaysis include:

- [Bulk Download Page](http://www.ncdc.noaa.gov/stormevents/ftp.jsp)
 - [Codebook](http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Export-Format.docx)
 - [README](http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/README)
 - [Directory of datasets](http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/)
- [Detailed information on the gathering of this data](http://www.ncdc.noaa.gov/stormevents/pd01016005curr.pdf)
- [Storm Data FAQ Page](http://www.ncdc.noaa.gov/stormevents/faq.jsp)


With the dataset in its current form, there are five primary variable columns
which are relevant to our research questions. They are:

The type of storm event:

- ***evtype*** : *factor* - The category name of the storm event observation

With respect to population health:

- ***fatalities*** : *numeric* - Fatalities. Deaths resulting directly from the
observed storm event.

- ***injuries*** : *numeric* - Injuries. Injuries directly resulting directly from
the observed storm event.

And with respect to local economies:

- ***propdmg*** : *numeric* - Monetary amount in USD of property damage resulting directly
from the observed storm event.

- ***cropdmg*** : *numeric* - Monetary amount in USD of crop damage resulting directly
from the observed storm event.

The local economy variables are effectively significands to a column vector of
exponents which can be translated into scientific notation.
(e.g. 10E6 = 1,000,000, or 3.5k = 3,500) and multiplied with the
monetary damage variables

- ***propdmgexp*** : *numeric* - An exponent of 10, together used to multiply with
**propdmg**

- ***cropdmgexp*** : *numeric* - An exponent of 10, together used to multiply with
**cropdmg**


The questions to answer are which events have the most impact on public health
and local economy. Using what we are given, we will devise simple model for
evaluating overall health impact by weighting both relevant variables and
adding them. We will do the same with the economy variables. More sophisticated
models could be used including those from this dataset which adjust weight of
the impact by year's past or include the overall or max impact into its
calculation. (And desired outside variables would include inflation and
indirect costs.) But for the sake of this project/report we are keeping the
model simple.

```{r impactmodelweights}
fatality.wt <- 3/4
injuries.wt <- 1 - fatality.wt

propdmg.wt <- 3/4
cropdmg.wt <- 1 - propdmg.wt
```

The models we use will be:

1. **Public Health Impact Value** = (`r fatality.wt`) * *fatalities* + (`r injuries.wt`) * *injuries*

2. **Local Economy Impact Value** = (`r propdmg.wt`) * *property damage* + (`r cropdmg.wt`) * *crop damage*



```{r downloadpreprocess, cache = TRUE}
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
file <- "./data/stormdata.csv.bz2"
# Not downloading it again due to data usage caps; pretend it just did.
#download.file(url, file)
s <- read.csv(bzfile(file), stringsAsFactors = FALSE)

## Restyle column names
colnames(s) <- tolower(colnames(s))
colnames(s) <- gsub("_", ".", colnames(s))
colnames(s)[1] <- "state"
```
This dataset is relatively large at the time of this writing, weighing in at:
```{r showdataframesize}
print(object.size(s), units = "Mb")
```
This is one reason we will build a clean, tidy dataset that is also slimmer.
But first, we need some functions to assist us in cleaning some of the columns-
more specifically, the economic value exponential variable columns.

```{r rawexpdata}
table(s$propdmgexp)
table(s$cropdmgexp)
```
A glimpse at the tables show us that approximately half of the values were
entered as-is and the others used a character to denote the place of the
value (i.e. 'M' or 'm' for millions, 'K' or 'k' for thousands). We can induce
that the integers represent the exponent of 10 as used in E notation (i.e. )
for multiplying the value (i.e. 5 represents a multiplyer of 10E5, or
10,000). Characters such as '-', '?', and '+' account for less than .002%
of the property damage data and less than .001% of the crop damage data:

```{r garbagevaluepercentiles}
round((sum(s$propdmgexp %in% c("-", '?', "+")) / nrow(s)) * 100, digits = 3)
round((sum(s$cropdmgexp %in% c("-", '?', "+")) / nrow(s)) * 100, digits = 3)
```

These garbage values are most likely user error and the associated values will
be considered entered as is.


```{r supportingcleaningfunctions}
## First a small function to assist us in adding upper case versions to the
## valid chars. If the uppercase versions of the valid characters change, then
## this code will likely need to be dropped and the building of the valid.chars
## variable be modified accordingly.
addUpper <- function(c) {
  cC <- c(c, toupper(c))
  return(cC)
}

## Function takes the column (vector) of the raw input for the exponential
## multiplier data found in propdmgexp and cropdmgexp and converts it to
## clean numerics.
cleanExpCol <- function(raw.col) {
  cleaned.col <- numeric(length(raw.col))
  ## Builds a character vector of the known characters/integers we know how to
  ## interpret.
  ##
  ## Note that we did not add 't' among them as it can stand for either 'tens'
  ## or 'trillions'. Common sense would have us rule out tens as it's so close
  ## to the actual value as to be ignored as a multiplier (although 1 itself is
  ## used as a multiplier a few times). More likely is an event that may cost
  ## trillions, and we need to be able to handle this multiplier in case of a
  ## "mega-event" like a tsunami hitting NYC or Godzilla. Therefore we recommend
  ## the use of the script in the future consider the events using a 't'
  ## mulitplier for the damage values on a case-by-case basis to determine
  ## whether the 't' is used to indicate a 'tens' or 'trillions' mulitplier, or
  ## was simply user error.
  
  ## Presently written to account for both upper and lower case
  hundred <- addUpper(c("h"))
  thousand <- addUpper(c("k"))
  million <- addUpper(c("m"))
  billion <- addUpper(c("b"))
  
  valid.chars <- c(hundred,
                   thousand,
                   million,
                   billion)
  
  
  ## We will do not include 1 since it is more likely the person entered it
  ## thinking it was meant to indicate the "ones' place". It will therefore
  ## be converted to zero along with everything not a valid character or
  ## integer.
  valid.ints <- 2:9
  
  ## Vectors of characters that will be converted to numeric exponential of 10
  ## First we build logical vectors for each int we want in our final column
  ## of multiplier exponents (i.e. 0 and 2 through 9)

  ## Also, this section would need to be modified by increasing the valid range
  ## for conversion beyond 9.
  to0 <- !(raw.col %in% valid.chars | raw.col %in% valid.ints)  

  ## I really didn't want to repeat myself here but the code below (or LOC equal
  ## to it) would more or less have to be written anyway due to the irregularity
  ## of the valid characters to convert from. There's a way no doubt, I'm just
  ## pressed for time to finish and probably am not as skilled in R to code it
  ## off the cuff.
  to2 <- raw.col == 2 | raw.col %in% hundred
  to3 <- raw.col == 3 | raw.col %in% thousand
  to4 <- raw.col == 4
  to5 <- raw.col == 5
  to6 <- raw.col == 6 | raw.col %in% million
  to7 <- raw.col == 7
  to8 <- raw.col == 8
  to9 <- raw.col == 9 | raw.col %in% billion

  cleaned.col[to0] <- 0
  
  for (i in valid.ints) {
    cleaned.col[get(paste0("to",i))] <- i
  }
  
  return(cleaned.col)
}

```

Now that our supporting column cleaning function is built, we are ready to
build the tidy dataframe.

```{r buildtidydataframe, cache = TRUE}
## Build a clean, tidy data frame from which to work with and call the data
## we want to analyze. This enables us to drop the monstrousity that is the
## original data frame we just imported.
e <- data.frame(id = 1:nrow(s))

e$date <- as.Date(s$bgn.date, "%m/%d/%Y %H:%M:%S")
e$year <- factor(format(e$date, format = "%Y"))
e$month <- factor(format(e$date, format = "%b"))
e$stateoffice <- s$stateoffic

e$evtype <- factor(tolower(s$evtype))
e$fatalities <- s$fatalities
e$injuries <- s$injuries
e$healthimp <- fatality.wt * e$fatalities + injuries.wt * e$injuries

e$propdmgsig <- s$propdmg
e$propdmgexp <- cleanExpCol(s$propdmgexp)
e$propdmg <- e$propdmgsig * 10^e$propdmgexp
e$cropdmgsig <- s$cropdmg
e$cropdmgexp <- cleanExpCol(s$cropdmgexp)
e$cropdmg <- e$cropdmgsig * 10^e$cropdmgexp
e$econimp <- propdmg.wt * e$propdmg + cropdmg.wt * e$cropdmg

rm(s)

```
We should note here that the evtype variable is really junked up and contains
numerous differentiations, misspellings, and conglomerations of the various
names for the categories of storm events. If this report were real, time would
need to be taken to clean that up as well- requiring much more manual
manipulation.

##Results

###Events most harmful with respect to population health?

```{r eventhealthimpact}
## Death and injuries totals and averages by event
hi.sum <- aggregate(healthimp ~ evtype, sum, data = e)
hi.ave <- aggregate(healthimp ~ evtype, mean, na.rm = TRUE, data = e)

t25.hi.sum <- hi.sum[with(hi.sum, order(healthimp, decreasing = TRUE, na.last = NA)), ][1:10, ]
t25.hi.ave <- hi.ave[with(hi.ave, order(healthimp, decreasing = TRUE, na.last = NA)), ][1:10, ]


p.hi.sum <- ggplot(t25.hi.sum, aes(evtype, healthimp, fill = evtype)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Total Health Impact") +
  xlab("Storm Event Type")

p.hi.ave <- ggplot(t25.hi.ave, aes(evtype, healthimp, fill = evtype)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Average Health Impact") +
  xlab("Storm Event Type")

grid.arrange(p.hi.sum, p.hi.ave, ncol = 1)
```

The charts tell us that the type of storm with the qualitatively worst impact to
human health are tornadoes. Not only are they dangerous, but there are a *lot*
of them. They still lead in average amount of health impact per storm event but
are not so outsized compared to the rest. In fact, the health impact of one
storm alone, Tropical Storm Gordon, is right there with the average health
impact of a tornado. The difference is that tropical storms and hurricanes
hit populated areas with much less frequency and are generally forecasted
days in advance. Tornadoes occur by in much shorter order. Also, the way events
such as tornadoes are counted may have something to do with their frequency:
tornadoes are counted as a separate storm event if they leave the ground and
touchdown 5 minutes apart or greater. Therefore the same tornado can be counted
as many different events. Hence, why the analysis on average impact was done so
that we can account for this property of the data collection.

###Events most harmful with respect to local economies?


```{r eventeconomyimpact}
## Death and injuries totals and averages by event
ei.sum <- aggregate(econimp ~ evtype, sum, data = e)
ei.ave <- aggregate(econimp ~ evtype, mean, na.rm = TRUE,  data = e)

t25.ei.sum <- ei.sum[with(ei.sum, order(econimp, decreasing = TRUE, na.last = NA)), ][1:10, ]
t25.ei.ave <- ei.ave[with(ei.ave, order(econimp, decreasing = TRUE, na.last = NA)), ][1:10, ]

p.ei.sum <- ggplot(t25.ei.sum, aes(evtype, econimp, fill = evtype)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Total Economical Impact") +
  xlab("Storm Event Type")
  

p.ei.ave <- ggplot(t25.ei.ave, aes(evtype, econimp, fill = evtype)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Average Economical Impact") +
  xlab("Storm Event Type")

grid.arrange(p.ei.sum, p.ei.ave, ncol = 1)
```

By far the largest amount of economical impact is from flooding, followed by
tornadoes, typhoons, and storm surges-nothing too surprising there. When we
look at average impact, tornadoes again result in the highest average amount of
damage in monetary terms. They are followed closely by
heavy rain/severe weather and hurricane/typhoon types of storm events.


